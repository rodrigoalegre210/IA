{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14fed10",
   "metadata": {},
   "source": [
    "### Redes Neuronales con Capas Ocultas.\n",
    "\n",
    "Situación: Quieres predecir si un estudiante aprueba (1) o no (0) basado en horas de estudio y horas de sueño.\n",
    "\n",
    "Usarás una red neuronal con una capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfe83a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones finales: [0.02560257 0.0328198  0.97466088 0.98386983 0.98379552]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos: [horas_estudio, horas_sueño]\n",
    "X = np.array([[2, 8], [3, 7], [4, 6], [5, 5], [6, 4]])\n",
    "y = np.array([0, 0, 1, 1, 1]) # 0 = No aprueba, 1 = Aprueba\n",
    "\n",
    "# Hiperparámetros.\n",
    "tasa_aprendizaje = 0.1\n",
    "epocas = 10000\n",
    "\n",
    "# Inicializar pesos y sesgos (aleatorios)\n",
    "# Capa oculta: 2 neuronas\n",
    "pesos_entrada_oculta = np.random.randn(2, 2) # 2 entradas, 2 neuronas ocultas.\n",
    "bias_ocultas = np.random.randn(2)\n",
    "\n",
    "# Capa salida: 1 neurona.\n",
    "pesos_oculta_salida = np.random.randn(2, 1)\n",
    "bias_salida = np.random.randn(1)\n",
    "\n",
    "# Función de activación sigmoide\n",
    "def sigmoide(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivada de la sigmoide (para backpropagation)\n",
    "def derivada_sigmoide(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(epocas):\n",
    "    # Forward propagation\n",
    "    # Capa oculta\n",
    "    z_oculta = np.dot(X, pesos_entrada_oculta) + bias_ocultas\n",
    "    activacion_oculta = sigmoide(z_oculta)\n",
    "\n",
    "    # Capa salida\n",
    "    z_salida = np.dot(activacion_oculta, pesos_oculta_salida) + bias_salida\n",
    "    activacion_salida = sigmoide(z_salida)\n",
    "\n",
    "    # Backpropagation\n",
    "    error = activacion_salida - y.reshape(-1, 1)\n",
    "\n",
    "    # Gradientes capa salida\n",
    "    delta_salida = error * derivada_sigmoide(activacion_salida)\n",
    "\n",
    "    # Gradientes capa oculta\n",
    "    error_oculta = delta_salida.dot(pesos_oculta_salida.T)\n",
    "    delta_oculta = error_oculta * derivada_sigmoide(activacion_oculta)\n",
    "\n",
    "    # Actualizar pesos y sesgos\n",
    "    pesos_oculta_salida -= tasa_aprendizaje * activacion_oculta.T.dot(delta_salida)\n",
    "    bias_salida -= tasa_aprendizaje * np.sum(delta_salida, axis = 0)\n",
    "\n",
    "    pesos_entrada_oculta -= tasa_aprendizaje * X.T.dot(delta_oculta)\n",
    "    bias_ocultas -= tasa_aprendizaje * np.sum(delta_oculta, axis = 0)\n",
    "\n",
    "# Predicción final\n",
    "predicciones = sigmoide(np.dot(sigmoide(np.dot(X, pesos_entrada_oculta) + bias_ocultas), pesos_oculta_salida) + bias_salida)\n",
    "print(\"Predicciones finales:\", predicciones.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a7389",
   "metadata": {},
   "source": [
    "* Forward propagation: Calcula las actividades capa por capa.\n",
    "* Backpropagation: Ajusta los pesos basado en el error.\n",
    "* Derivada de la sigmoide: Crucial para calcular gradientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3095db4",
   "metadata": {},
   "source": [
    "Modifica el código para tener:\n",
    "\n",
    "1. 3 neuronas en la capa oculta.\n",
    "2. Función de activación ReLU en la capa oculta (y su derivada)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
